{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "import quandl #https://docs.quandl.com/docs/python-time-series give a how to guide\n",
    "from config import q_api_key\n",
    "from config import y_api_key\n",
    "from config import c_api_key\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from census import Census\n",
    "c = Census(c_api_key, year=2017)\n",
    "\n",
    "\n",
    "from uszipcode import SearchEngine, SimpleZipcode, Zipcode #https://uszipcode.readthedocs.io/index.html\n",
    "#create a variable for the searchengine function which pulls down all lat/longs in database for crime/airbnb data (lat/long to zip)\n",
    "search = SearchEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this call to set the api_key for zillow data\n",
    "quandl.ApiConfig.api_key = q_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Zipcode\n",
       "0    60601\n",
       "1    60602\n",
       "2    60603\n",
       "3    60604\n",
       "4    60605"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipcode_df=pd.read_csv(\"zipcode.csv\")\n",
    "zipcode_df['Zipcode'] = pd.to_numeric(zipcode_df['Zipcode'])\n",
    "zipcode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulled rent data for 60601\n",
      "Pulled home value data for 60601\n",
      "Pulled rent data for 60602\n",
      "Home value data for 60602 not found\n",
      "Pulled rent data for 60603\n",
      "Home value data for 60603 not found\n",
      "Pulled rent data for 60604\n",
      "Home value data for 60604 not found\n",
      "Pulled rent data for 60605\n",
      "Pulled home value data for 60605\n",
      "Pulled rent data for 60606\n",
      "Pulled home value data for 60606\n",
      "Pulled rent data for 60607\n",
      "Pulled home value data for 60607\n",
      "Pulled rent data for 60608\n",
      "Pulled home value data for 60608\n",
      "Pulled rent data for 60609\n",
      "Pulled home value data for 60609\n",
      "Pulled rent data for 60610\n",
      "Pulled home value data for 60610\n",
      "Pulled rent data for 60611\n",
      "Pulled home value data for 60611\n",
      "Pulled rent data for 60612\n",
      "Pulled home value data for 60612\n",
      "Pulled rent data for 60613\n",
      "Pulled home value data for 60613\n",
      "Pulled rent data for 60614\n",
      "Pulled home value data for 60614\n",
      "Pulled rent data for 60615\n",
      "Pulled home value data for 60615\n",
      "Pulled rent data for 60616\n",
      "Pulled home value data for 60616\n",
      "Pulled rent data for 60617\n",
      "Home value data for 60617 not found\n",
      "Pulled rent data for 60618\n",
      "Pulled home value data for 60618\n",
      "Pulled rent data for 60619\n",
      "Pulled home value data for 60619\n",
      "Pulled rent data for 60620\n",
      "Pulled home value data for 60620\n",
      "Pulled rent data for 60621\n",
      "Home value data for 60621 not found\n",
      "Pulled rent data for 60622\n",
      "Pulled home value data for 60622\n",
      "Pulled rent data for 60623\n",
      "Home value data for 60623 not found\n",
      "Pulled rent data for 60624\n",
      "Pulled home value data for 60624\n",
      "Pulled rent data for 60625\n",
      "Pulled home value data for 60625\n",
      "Pulled rent data for 60626\n",
      "Pulled home value data for 60626\n",
      "Pulled rent data for 60628\n",
      "Home value data for 60628 not found\n",
      "Pulled rent data for 60629\n",
      "Pulled home value data for 60629\n",
      "Pulled rent data for 60630\n",
      "Pulled home value data for 60630\n",
      "Pulled rent data for 60631\n",
      "Pulled home value data for 60631\n",
      "Pulled rent data for 60632\n",
      "Pulled home value data for 60632\n",
      "Pulled rent data for 60633\n",
      "Pulled home value data for 60633\n",
      "Pulled rent data for 60634\n",
      "Pulled home value data for 60634\n",
      "Pulled rent data for 60636\n",
      "Home value data for 60636 not found\n",
      "Pulled rent data for 60637\n",
      "Pulled home value data for 60637\n",
      "Pulled rent data for 60638\n",
      "Pulled home value data for 60638\n",
      "Pulled rent data for 60639\n",
      "Pulled home value data for 60639\n",
      "Pulled rent data for 60640\n",
      "Pulled home value data for 60640\n",
      "Pulled rent data for 60641\n",
      "Pulled home value data for 60641\n",
      "Pulled rent data for 60642\n",
      "Pulled home value data for 60642\n",
      "Pulled rent data for 60643\n",
      "Pulled home value data for 60643\n",
      "Pulled rent data for 60644\n",
      "Pulled home value data for 60644\n",
      "Pulled rent data for 60645\n",
      "Pulled home value data for 60645\n",
      "Pulled rent data for 60646\n",
      "Pulled home value data for 60646\n",
      "Pulled rent data for 60647\n",
      "Pulled home value data for 60647\n",
      "Pulled rent data for 60649\n",
      "Home value data for 60649 not found\n",
      "Pulled rent data for 60651\n",
      "Pulled home value data for 60651\n",
      "Pulled rent data for 60652\n",
      "Pulled home value data for 60652\n",
      "Pulled rent data for 60653\n",
      "Pulled home value data for 60653\n",
      "Pulled rent data for 60654\n",
      "Pulled home value data for 60654\n",
      "Pulled rent data for 60655\n",
      "Pulled home value data for 60655\n",
      "Pulled rent data for 60656\n",
      "Pulled home value data for 60656\n",
      "Pulled rent data for 60657\n",
      "Pulled home value data for 60657\n",
      "Pulled rent data for 60659\n",
      "Pulled home value data for 60659\n",
      "Pulled rent data for 60660\n",
      "Pulled home value data for 60660\n",
      "Pulled rent data for 60661\n",
      "Pulled home value data for 60661\n",
      "Pulled rent data for 60706\n",
      "Pulled home value data for 60706\n",
      "Pulled rent data for 60707\n",
      "Pulled home value data for 60707\n",
      "Pulled rent data for 60803\n",
      "Pulled home value data for 60803\n",
      "Pulled rent data for 60804\n",
      "Pulled home value data for 60804\n",
      "Pulled rent data for 60805\n",
      "Pulled home value data for 60805\n",
      "[1944.0, 1666.0, 1630.0, 1835.0, 1865.0, 1910.0, 1937.0, 1698.0, 1455.0, 1874.0, 1928.0, 1713.0, 1640.0, 2193.0, 1576.0, 1741.0, 1395.0, 1977.0, 1429.0, 1424.0, 1348.0, 2221.0, 1441.0, 1470.0, 1841.0, 1495.0, 1391.0, 1488.0, 1946.0, 2045.0, 1528.0, 1395.0, 1858.0, 1349.0, 1443.0, 1634.0, 1719.0, 1642.0, 1880.0, 2209.0, 1478.0, 1507.0, 1620.0, 2250.0, 1955.0, 1372.0, 1536.0, 1520.0, 1666.0, 1867.0, 1755.0, 1890.0, 1990.0, 1860.0, 1567.0, 1855.0, 1898.0, 1839.0, 1560.0, 1481.0, 1566.0]\n",
      "[391000.0, 'NaN', 'NaN', 'NaN', 284200.0, 407000.0, 355900.0, 258700.0, 165800.0, 296900.0, 351800.0, 260700.0, 229300.0, 432000.0, 192100.0, 276400.0, 'NaN', 392700.0, 129900.0, 125600.0, 'NaN', 446800.0, 'NaN', 127100.0, 295300.0, 177000.0, 'NaN', 170000.0, 298300.0, 332800.0, 176900.0, 110600.0, 267600.0, 'NaN', 133600.0, 215200.0, 232300.0, 237200.0, 278700.0, 453300.0, 148700.0, 131200.0, 215600.0, 385800.0, 393900.0, 'NaN', 163700.0, 172600.0, 231400.0, 341400.0, 238900.0, 284600.0, 352800.0, 277100.0, 203700.0, 322900.0, 279300.0, 249400.0, 163800.0, 177300.0, 182700.0]\n"
     ]
    }
   ],
   "source": [
    "#pull in zipcode list\n",
    "zipcode_df=pd.read_csv(\"zipcode.csv\")\n",
    "zipcode_df['Zipcode'] = pd.to_numeric(zipcode_df['Zipcode'])\n",
    "#turn zipcode into a list\n",
    "zipcodes = zipcode_df['Zipcode'].tolist()\n",
    "\n",
    "#ZILLOW DATA\n",
    "#create a blank list for median home values and median rent from Zillow\n",
    "medianrent=[]\n",
    "medianhomevalues=[]\n",
    "#pull median home value for each zip code in Chicago at the yearly level for 2018 only\n",
    "for x in range(0,len(zipcodes)):\n",
    "    try:\n",
    "        mr_raw=quandl.get(f\"ZILLOW/Z{zipcodes[x]}_ZRIAH\", collapse=\"annual\", start_date=\"2018-12-31\", end_date=\"2018-12-31\")\n",
    "        mr_list=mr_raw[\"Value\"].tolist()\n",
    "        medianrent.append(mr_list[0])\n",
    "        print(f'Pulled rent data for {zipcodes[x]}')\n",
    "    except:\n",
    "        mr_missing='NaN'\n",
    "        medianrent.append(mr_missing)\n",
    "        print(f'Rent data for {zipcodes[x]} not found')\n",
    "    try:\n",
    "        mhv_raw=quandl.get(f\"ZILLOW/Z{zipcodes[x]}_ZHVIAH\", collapse=\"annual\", start_date=\"2018-12-31\", end_date=\"2018-12-31\")\n",
    "        mhv_list=mhv_raw[\"Value\"].tolist()\n",
    "        medianhomevalues.append(mhv_list[0])\n",
    "        print(f'Pulled home value data for {zipcodes[x]}')\n",
    "    except:\n",
    "        mhv_missing='NaN'\n",
    "        medianhomevalues.append(mhv_missing)\n",
    "        print(f'Home value data for {zipcodes[x]} not found')\n",
    "print(medianrent)\n",
    "print(medianhomevalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Median Rent</th>\n",
       "      <th>Median Home Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60601</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>391000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60602</td>\n",
       "      <td>1666.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60603</td>\n",
       "      <td>1630.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60604</td>\n",
       "      <td>1835.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60605</td>\n",
       "      <td>1865.0</td>\n",
       "      <td>284200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Zipcode  Median Rent Median Home Value\n",
       "0    60601       1944.0            391000\n",
       "1    60602       1666.0               NaN\n",
       "2    60603       1630.0               NaN\n",
       "3    60604       1835.0               NaN\n",
       "4    60605       1865.0            284200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe of zipcode, median rent, and median home values\n",
    "housing_df = pd.DataFrame({\"Zipcode\":zipcodes, \"Median Rent\":medianrent, \"Median Home Value\":medianhomevalues})\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting datapull for 60601\n",
      "finished datapull for 60601\n",
      "new appended category total: 48  for 60601\n",
      "starting datapull for 60602\n",
      "finished datapull for 60602\n",
      "new appended category total: 11  for 60602\n",
      "starting datapull for 60603\n",
      "finished datapull for 60603\n",
      "new appended category total: 22  for 60603\n",
      "starting datapull for 60604\n",
      "finished datapull for 60604\n",
      "new appended category total: 5  for 60604\n",
      "starting datapull for 60605\n",
      "finished datapull for 60605\n",
      "new appended category total: 34  for 60605\n",
      "starting datapull for 60606\n",
      "finished datapull for 60606\n",
      "new appended category total: 22  for 60606\n",
      "starting datapull for 60607\n",
      "finished datapull for 60607\n",
      "new appended category total: 81  for 60607\n",
      "starting datapull for 60608\n",
      "finished datapull for 60608\n",
      "new appended category total: 34  for 60608\n",
      "starting datapull for 60609\n",
      "finished datapull for 60609\n",
      "new appended category total: 10  for 60609\n",
      "starting datapull for 60610\n",
      "finished datapull for 60610\n",
      "new appended category total: 71  for 60610\n",
      "starting datapull for 60611\n",
      "finished datapull for 60611\n",
      "new appended category total: 96  for 60611\n",
      "starting datapull for 60612\n",
      "finished datapull for 60612\n",
      "new appended category total: 12  for 60612\n",
      "starting datapull for 60613\n",
      "finished datapull for 60613\n",
      "new appended category total: 77  for 60613\n",
      "starting datapull for 60614\n",
      "finished datapull for 60614\n",
      "new appended category total: 113  for 60614\n",
      "starting datapull for 60615\n",
      "finished datapull for 60615\n",
      "new appended category total: 12  for 60615\n",
      "starting datapull for 60616\n",
      "finished datapull for 60616\n",
      "new appended category total: 39  for 60616\n",
      "starting datapull for 60617\n",
      "finished datapull for 60617\n",
      "new appended category total: 10  for 60617\n",
      "starting datapull for 60618\n",
      "finished datapull for 60618\n",
      "new appended category total: 87  for 60618\n",
      "starting datapull for 60619\n",
      "finished datapull for 60619\n",
      "new appended category total: 12  for 60619\n",
      "starting datapull for 60620\n",
      "finished datapull for 60620\n",
      "new appended category total: 8  for 60620\n",
      "starting datapull for 60621\n",
      "finished datapull for 60621\n",
      "new appended category total: 2  for 60621\n",
      "starting datapull for 60622\n",
      "finished datapull for 60622\n",
      "new appended category total: 108  for 60622\n",
      "starting datapull for 60623\n",
      "finished datapull for 60623\n",
      "new appended category total: 6  for 60623\n",
      "starting datapull for 60624\n",
      "finished datapull for 60624\n",
      "new appended category total: 1  for 60624\n",
      "starting datapull for 60625\n",
      "finished datapull for 60625\n",
      "new appended category total: 46  for 60625\n",
      "starting datapull for 60626\n",
      "finished datapull for 60626\n",
      "new appended category total: 22  for 60626\n",
      "starting datapull for 60628\n",
      "finished datapull for 60628\n",
      "new appended category total: 4  for 60628\n",
      "starting datapull for 60629\n",
      "finished datapull for 60629\n",
      "new appended category total: 9  for 60629\n",
      "starting datapull for 60630\n",
      "finished datapull for 60630\n",
      "new appended category total: 32  for 60630\n",
      "starting datapull for 60631\n",
      "finished datapull for 60631\n",
      "new appended category total: 15  for 60631\n",
      "starting datapull for 60632\n",
      "finished datapull for 60632\n",
      "new appended category total: 16  for 60632\n",
      "starting datapull for 60633\n",
      "finished datapull for 60633\n",
      "new appended category total: 8  for 60633\n",
      "starting datapull for 60634\n",
      "finished datapull for 60634\n",
      "new appended category total: 32  for 60634\n",
      "starting datapull for 60636\n",
      "finished datapull for 60636\n",
      "new appended category total: 1  for 60636\n",
      "starting datapull for 60637\n",
      "finished datapull for 60637\n",
      "new appended category total: 6  for 60637\n",
      "starting datapull for 60638\n",
      "finished datapull for 60638\n",
      "new appended category total: 31  for 60638\n",
      "starting datapull for 60639\n",
      "finished datapull for 60639\n",
      "new appended category total: 15  for 60639\n",
      "starting datapull for 60640\n",
      "finished datapull for 60640\n",
      "new appended category total: 51  for 60640\n",
      "starting datapull for 60641\n",
      "finished datapull for 60641\n",
      "new appended category total: 33  for 60641\n",
      "starting datapull for 60642\n",
      "finished datapull for 60642\n",
      "new appended category total: 31  for 60642\n",
      "starting datapull for 60643\n",
      "finished datapull for 60643\n",
      "new appended category total: 14  for 60643\n",
      "starting datapull for 60644\n",
      "finished datapull for 60644\n",
      "new appended category total: 3  for 60644\n",
      "starting datapull for 60645\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f731c3534cc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         }\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m#combine page with previous pages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    531\u001b[0m         }\n\u001b[0;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Unexpected EOF'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1819\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1820\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1821\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1822\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#YELP DATA\n",
    "#found in https://python.gotrained.com/yelp-fusion-api-tutorial/\n",
    "headers = {'Authorization': 'Bearer %s' % y_api_key}\n",
    "\n",
    "#category of business you want to pull 1. nightlife\n",
    "categories = 'nightlife' \n",
    "#base url\n",
    "url='https://api.yelp.com/v3/businesses/search'\n",
    "#create a list for the number of returned categories in zipcode\n",
    "category_l = []\n",
    "#for every zipcode in the list return all businesses for the category searched and get rid of entries not within the zip and add to a total list\n",
    "for zipcode in zipcodes:\n",
    "    print(f'starting datapull for {zipcode}')\n",
    "    #create a list for all the pages returned\n",
    "    yelp_data = []\n",
    "    #the max returned businesses is 1000 and you can have 50 on a page so create a for loop to iterate through until get 400 code\n",
    "    #https://stackoverflow.com/questions/35525994/how-to-request-more-than-20-results-from-yelp-api\n",
    "    for offset in range(0, 1000, 50):\n",
    "        params = {\n",
    "            'limit': 50, \n",
    "            'location': zipcode,\n",
    "            'categories': categories,\n",
    "            'offset': offset\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            #combine page with previous pages\n",
    "            yelp_data += response.json()['businesses']\n",
    "        elif response.status_code == 400:\n",
    "            print('400 Bad Request')\n",
    "            break\n",
    "    print(f'finished datapull for {zipcode}')\n",
    "    #create a blank zipcode list in preparation of pulling in zipcodes for each entry collected in the above yelp_data\n",
    "    zipcode_b =[]\n",
    "    #for each business in the yelp_data json, find the zip code and then append it to the zipcode_b list\n",
    "    for business in range(0,len(yelp_data)):\n",
    "        currentzip =str(yelp_data[business][\"location\"][\"zip_code\"])\n",
    "        if currentzip == str(zipcode):\n",
    "            zipcode_b.append(currentzip)\n",
    "            #print(currentzip)\n",
    "       # else:\n",
    "        #    print(f'Not correct zip :{currentzip} != {zipcode}')\n",
    "    #add to the category list with total number of categories from current zipcode you are looking at\n",
    "    numberinzip=len(zipcode_b)\n",
    "    category_l.append(numberinzip)\n",
    "    print(f'new appended category total: {numberinzip}  for {zipcode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#category of business you want to pull 2. restaurants\n",
    "categories = 'restaurants' \n",
    "#base url\n",
    "url='https://api.yelp.com/v3/businesses/search'\n",
    "#create a list for the number of returned categories in zipcode\n",
    "category_r = []\n",
    "#for every zipcode in the list return all businesses for the category searched and get rid of entries not within the zip and add to a total list\n",
    "for zipcode in zipcodes:\n",
    "    print(f'starting datapull for {zipcode}')\n",
    "    #create a list for all the pages returned\n",
    "    yelp_data = []\n",
    "    #the max returned businesses is 1000 and you can have 50 on a page so create a for loop to iterate through until get 400 code\n",
    "    #https://stackoverflow.com/questions/35525994/how-to-request-more-than-20-results-from-yelp-api\n",
    "    for offset in range(0, 1000, 50):\n",
    "        params = {\n",
    "            'limit': 50, \n",
    "            'location': zipcode,\n",
    "            'categories': categories,\n",
    "            'offset': offset\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            #combine page with previous pages\n",
    "            yelp_data += response.json()['businesses']\n",
    "        elif response.status_code == 400:\n",
    "            print('400 Bad Request')\n",
    "            break\n",
    "    print(f'finished datapull for {zipcode}')\n",
    "    #create a blank zipcode list in preparation of pulling in zipcodes for each entry collected in the above yelp_data\n",
    "    zipcode_b =[]\n",
    "    #for each business in the yelp_data json, find the zip code and then append it to the zipcode_b list\n",
    "    for business in range(0,len(yelp_data)):\n",
    "        currentzip =str(yelp_data[business][\"location\"][\"zip_code\"])\n",
    "        if currentzip == str(zipcode):\n",
    "            zipcode_b.append(currentzip)\n",
    "            #print(currentzip)\n",
    "       # else:\n",
    "        #    print(f'Not correct zip :{currentzip} != {zipcode}')\n",
    "    #add to the category list with total number of categories from current zipcode you are looking at\n",
    "    numberinzip=len(zipcode_b)\n",
    "    category_r.append(numberinzip)\n",
    "    print(f'new appended category total: {numberinzip}  for {zipcode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#category of business you want to pull 3. grocery\n",
    "categories = 'grocery' \n",
    "#base url\n",
    "url='https://api.yelp.com/v3/businesses/search'\n",
    "#create a list for the number of returned categories in zipcode\n",
    "category_g = []\n",
    "#for every zipcode in the list return all businesses for the category searched and get rid of entries not within the zip and add to a total list\n",
    "for zipcode in zipcodes:\n",
    "    print(f'starting datapull for {zipcode}')\n",
    "    #create a list for all the pages returned\n",
    "    yelp_data = []\n",
    "    #the max returned businesses is 1000 and you can have 50 on a page so create a for loop to iterate through until get 400 code\n",
    "    #https://stackoverflow.com/questions/35525994/how-to-request-more-than-20-results-from-yelp-api\n",
    "    for offset in range(0, 1000, 50):\n",
    "        params = {\n",
    "            'limit': 50, \n",
    "            'location': zipcode,\n",
    "            'categories': categories,\n",
    "            'offset': offset\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            #combine page with previous pages\n",
    "            yelp_data += response.json()['businesses']\n",
    "        elif response.status_code == 400:\n",
    "            print('400 Bad Request')\n",
    "            break\n",
    "    print(f'finished datapull for {zipcode}')\n",
    "    #create a blank zipcode list in preparation of pulling in zipcodes for each entry collected in the above yelp_data\n",
    "    zipcode_b =[]\n",
    "    #for each business in the yelp_data json, find the zip code and then append it to the zipcode_b list\n",
    "    for business in range(0,len(yelp_data)):\n",
    "        currentzip =str(yelp_data[business][\"location\"][\"zip_code\"])\n",
    "        if currentzip == str(zipcode):\n",
    "            zipcode_b.append(currentzip)\n",
    "            #print(currentzip)\n",
    "       # else:\n",
    "        #    print(f'Not correct zip :{currentzip} != {zipcode}')\n",
    "    #add to the category list with total number of categories from current zipcode you are looking at\n",
    "    numberinzip=len(zipcode_b)\n",
    "    category_g.append(numberinzip)\n",
    "    print(f'new appended category total: {numberinzip}  for {zipcode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine nightlife, restaurant and grocery with zipcode into dataframe\n",
    "yelp_complete=pd.DataFrame({\"Zipcode\":zipcodes, \"Total Nightlife\": category_l, \"Total Restaurant\": category_r, \n",
    "                      \"Total Grocery\": category_g})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.689079</td>\n",
       "      <td>-87.696064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.763181</td>\n",
       "      <td>-87.657709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.740521</td>\n",
       "      <td>-87.647391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.857068</td>\n",
       "      <td>-87.657625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.751914</td>\n",
       "      <td>-87.647717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude\n",
       "0  41.689079 -87.696064\n",
       "1  41.763181 -87.657709\n",
       "2  41.740521 -87.647391\n",
       "3  41.857068 -87.657625\n",
       "4  41.751914 -87.647717"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CRIME DATA\n",
    "#read in crime data\n",
    "df_crime = pd.read_csv('Crimes_2018.csv')\n",
    "df_crime_latlon=df_crime.loc[:,['Latitude', 'Longitude']]\n",
    "df_crime_latlon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263455"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_crime_latlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uszipcode import SearchEngine, SimpleZipcode, Zipcode\n",
    "search = SearchEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "#for every row in df_crime_latlon\n",
    "for index, row in df_crime_latlon.iterrows():\n",
    "    #part of uszipcode library it takes the lat/lon from the row you are in and looks for the nearest zip (returns=1) \n",
    "    #in a 3 mile radius\n",
    "    result = search.by_coordinates(row[\"Latitude\"], row[\"Longitude\"], radius=3, returns=1)\n",
    "    #append to res\n",
    "    res.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263455"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a blank list for zipcodes\n",
    "zipcodes= []\n",
    "#for every entry returned in res\n",
    "for i in range(len(res)):\n",
    "    #this is a list of lists so for every entry there is another list inside that contains geographical information\n",
    "    for x in res[i]:\n",
    "        # zipcode is from uszipcode library and find the zipcode in the list\n",
    "        zip = x.zipcode\n",
    "     #   first = res[i]\n",
    "        #append the zipcode to the zipcodes list\n",
    "        zipcodes.append(zip)\n",
    "#     zipcodes.append(first)\n",
    "len(zipcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe of zipcodes\n",
    "zip_df = pd.DataFrame({\"Zipcode\": zipcodes})\n",
    "#count number of zip codes and reset index so zip code becomes a column\n",
    "zipcode_count = zip_df[\"Zipcode\"].value_counts().reset_index()\n",
    "#rename the variables and output to csv\n",
    "zipcode_count_rename = zipcode_count.rename(columns={\"index\": \"Zipcode\",\"Zipcode\":\"Crime Count\"})\n",
    "zipcode_count_rename.to_csv(\"Crime_Count by zip.csv\", encoding=\"utf-8\", index=False)\n",
    "#make sure zipcode is numeric\n",
    "zipcode_count_rename['Zipcode'] = pd.to_numeric(zipcode_count_rename['Zipcode'])\n",
    "#output to csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export data to csv\n",
    "housing_df.to_csv(\"housing_data.csv\", encoding=\"utf-8\", index=False)\n",
    "yelp_complete.to_csv(\"yelp_data.csv\", encoding=\"utf-8\", index=False)\n",
    "zipcode_count_rename.to_csv(\"crime_count_by_zip.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Census Search to retrieve data on all zip codes (2013 ACS5 Census)\n",
    "# See: https://github.com/CommerceDataService/census-wrapper for library documentation\n",
    "# See: https://gist.github.com/afhaque/60558290d6efd892351c4b64e5c01e9b for labels\n",
    "\n",
    "census_data = c.acs5.get((\"NAME\", \"B19013_001E\", \"B01003_001E\", \"B01002_001E\",\n",
    "                          \"B19301_001E\",\n",
    "                          \"B17001_002E\"), {'for': 'zip code tabulation area:*'})\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "census_pd = pd.DataFrame(census_data)\n",
    "\n",
    "   \n",
    "\n",
    "# Column Reordering\n",
    "census_pd = census_pd.rename(columns={\"B01003_001E\": \"Population\",\n",
    "                                      \"B01002_001E\": \"Median Age\",\n",
    "                                      \"B19013_001E\": \"Household Income\",\n",
    "                                      \"B19301_001E\": \"Per Capita Income\",\n",
    "                                      \"B17001_002E\": \"Poverty Count\",\n",
    "                                      \"NAME\": \"Name\", \"zip code tabulation area\": \"Zipcode\"})\n",
    "# Add in Poverty Rate (Poverty Count / Population)\n",
    "census_pd[\"Poverty Rate\"] = 100 * \\\n",
    "    census_pd[\"Poverty Count\"].astype(\n",
    "        int) / census_pd[\"Population\"].astype(int)\n",
    "# Final DataFrame\n",
    "census_pd = census_pd[[\"Zipcode\", \"Population\", \"Median Age\", \"Household Income\",\n",
    "                       \"Per Capita Income\", \"Poverty Count\", \"Poverty Rate\"]]\n",
    "census_pd['Zipcode'] = pd.to_numeric(census_pd['Zipcode'])\n",
    "census_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_census_df = pd.merge(zipcode_df, census_pd, on=\"Zipcode\")\n",
    "chicago_census_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_census_df =  pd.merge(housing_df, chicago_census_df, on=\"Zipcode\")\n",
    "housing_census_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot rent vs home value to analyze which variable to use as y variable in regression/comp with other variables\n",
    "# fig, ax1 = plt.subplots()\n",
    "# ax1.set_facecolor(\"lavender\")\n",
    "# plt.scatter(medianrent,medianhomevalues, edgecolor=\"black\", c=\"blue\", marker='o')\n",
    "# plt.grid(color=\"white\")\n",
    "# plt.title(\"Median Rent vs. Median Home Values by Zipcode\")\n",
    "# plt.ylabel(\"Median Home Values\")\n",
    "# plt.xlabel(\"Median Rent\")\n",
    "# plt.savefig('Median Rent vs Median Home Value.png', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
